# Project Overview

---


**Generated by [project2md](https://pypi.org/project/project2md) vunknown** 
on 2025-07-20 15:18:12


ðŸ” **Signatures Mode**: This output contains only function signatures and markdown headers. 
Function bodies and detailed markdown content have been omitted for a high-level overview.


ðŸ“ **Source**: [GitHub Repository](https://github.com/itsatony/project2md)


---


## README.md Content


# MEDIABASE: Cancer Transcriptome Base [lines:3]
## Overview [lines:14]
## ETL Data Integration Philosophy [lines:3]
### Why Downloadable Datasets? [lines:8]
### Data Source Strategy [lines:7]
### Implementation Benefits [lines:8]
## Setup [lines:1]
### Prerequisites [lines:5]
### Environment Setup [lines:31]
### Database Setup [lines:15]
### Development [lines:37]
## Quick Start [lines:30]
## ETL Processor Modules [lines:1]
### Transcript Processor [lines:4]
# Run only transcript processing [lines:8]
### Product Classification [lines:4]
# Run only product classification [lines:7]
### GO Term Enrichment [lines:4]
# Run only GO term enrichment [lines:13]
### Pathway Enrichment [lines:4]
# Run only pathway enrichment [lines:11]
### Drug Integration [lines:4]
# Run drug integration with DrugCentral (default) [lines:2]
# Run drug integration with ChEMBL [lines:2]
# Run ChEMBL drug integration directly with filtering for clinical phase [lines:19]
### Drug Repurposing Hub Integration [lines:4]
# Run Drug Repurposing Hub integration [lines:7]
### PharmGKB Pharmacogenomic Annotations [lines:4]
# Run PharmGKB annotations integration [lines:54]
### Clinical Trials Integration [lines:4]
# Run ClinicalTrials.gov integration [lines:36]
### Evidence Scoring System [lines:4]
# Run evidence scoring as part of ETL pipeline [lines:2]
# Run evidence scoring standalone [lines:58]
### Publication Enrichment & Quality Scoring [lines:4]
# Run comprehensive publication enrichment [lines:5]
#### **Phase 1: Multi-Source Publication Extraction** âœ… **IMPLEMENTED** [lines:5]
#### **Phase 2: ChEMBL Publications Integration** âœ… **IMPLEMENTED** [lines:5]
#### **Phase 3: ClinicalTrials.gov API Integration** âœ… **IMPLEMENTED** [lines:5]
#### **Phase 4: Publication Quality Scoring** âœ… **IMPLEMENTED** [lines:8]
# Publication quality scoring [lines:28]
## Patient Copy Functionality [lines:3]
### Quick Start [lines:2]
# Create patient-specific database with fold-change data [lines:4]
# Validate CSV data without making changes (dry run) [lines:5]
# List all patient databases [lines:2]
# Delete patient databases with confirmation [lines:3]
### CSV Data Requirements [lines:10]
### Example CSV Format [lines:10]
### Example Patient Data Files [lines:9]
### Clinical Workflow [lines:7]
### Features [lines:7]
## Database Schema and Structure [lines:3]
### Current Schema Version: v0.1.9 (Enhanced with PharmGKB Variant Annotations) [lines:17]
### Core Table: cancer_transcript_base [lines:34]
### Complete Example Record [lines:244]
### Key Features for Oncological Analysis [lines:23]
### Database Indexes [lines:31]
### Patient-Specific Schema [lines:8]
## Query Examples and Analysis [lines:1]
### Dynamic Queries - Human Language to SQL [lines:3]
#### Query 1: "Which genes are significantly upregulated in this patient?" [lines:30]
#### Query 2: "What drugs target the overexpressed genes in my patient?" [lines:20]
#### Query 3: "Which pathways are disrupted based on my patient's expression profile?" [lines:34]
#### Query 4: "Are there any published studies relevant to my patient's gene expression pattern?" [lines:33]
#### Query 5: "Which clinical trials are relevant to my patient's upregulated genes?" [lines:40]
#### Query 6: "What is the publication evidence strength for my top dysregulated genes?" [lines:73]
#### Query 7: "Which genes have the strongest multi-source publication support?" [lines:58]
#### Query 8: "What pharmacogenomic variants should I consider for drug therapy?" *(NEW v0.1.9)* [lines:77]
### Standard Oncological Analysis (SOTA) Queries [lines:3]
#### SOTA Query 1: Oncogene and Tumor Suppressor Analysis [lines:66]
#### SOTA Query 2: Therapeutic Target Prioritization [lines:69]
#### SOTA Query 3: Pathway-Based Therapeutic Strategy [lines:87]
### Query Validation Results [lines:4]
# Test SOTA Query 1 - Oncogene Analysis [lines:17]
#### SOTA Query 4: Pharmacogenomic Variant Analysis *(NEW v0.1.9)* [lines:99]
### Automated SOTA Analysis Pipeline [lines:4]
# Run complete SOTA analysis on main database [lines:2]
# Analyze specific patient database [lines:2]
# Generate JSON report for LLM processing [lines:48]
### Query Validation [lines:4]
# Test query syntax and compatibility [lines:2]
# Validate against specific patient database [lines:3]
## Documentation [lines:8]
## Project Status and Progress [lines:338]
### 2023-XX-XX: Removed Legacy Migration Support [lines:5]
### 2023-XX-XX: Enhanced Database Management [lines:8]
## Database Management [lines:3]
### Features [lines:9]
### Usage [lines:47]
### Environment Configuration [lines:4]
# Database Configuration [lines:6]
# API Configuration [lines:4]
# Data Sources [lines:11]
# Cache and Processing [lines:6]
# Security [lines:5]
## Specialized Schema Support [lines:62]
## Contributing [lines:7]
## License [lines:3]


## Project Structure


```tree

â””â”€â”€ mediabase
    â”œâ”€â”€ CLAUDE.md
    â”œâ”€â”€ README.md
    â”œâ”€â”€ config
    â”‚   â”œâ”€â”€ etl_sequence.py
    â”‚   â””â”€â”€ settings.py
    â”œâ”€â”€ docs
    â”‚   â”œâ”€â”€ api.md
    â”‚   â”œâ”€â”€ architecture.md
    â”‚   â”œâ”€â”€ current_etl_issues.md
    â”‚   â”œâ”€â”€ data_source_schemas.md
    â”‚   â”œâ”€â”€ deployment.md
    â”‚   â”œâ”€â”€ etl_action_plan.md
    â”‚   â”œâ”€â”€ etl_improvement_plan.md
    â”‚   â”œâ”€â”€ evidence_scoring.md
    â”‚   â”œâ”€â”€ evidence_scoring_framework.md
    â”‚   â”œâ”€â”€ patient_copy_guide.md
    â”‚   â”œâ”€â”€ postgres_setup_guide.md
    â”‚   â”œâ”€â”€ publication_enhancement_plan.md
    â”‚   â””â”€â”€ publication_references.md
    â”œâ”€â”€ scripts
    â”‚   â”œâ”€â”€ create_patient_copy.py
    â”‚   â”œâ”€â”€ manage_db.py
    â”‚   â”œâ”€â”€ manage_patient_databases.py
    â”‚   â”œâ”€â”€ run_chembl_enrichment.py
    â”‚   â”œâ”€â”€ run_etl.py
    â”‚   â”œâ”€â”€ run_evidence_scoring.py
    â”‚   â”œâ”€â”€ run_sota_analysis.py
    â”‚   â”œâ”€â”€ validate_queries.py
    â”‚   â””â”€â”€ verify_db_schema.py
    â”œâ”€â”€ src
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ api
    â”‚   â”‚   â””â”€â”€ queries.py
    â”‚   â”œâ”€â”€ config
    â”‚   â”‚   â””â”€â”€ constants.py
    â”‚   â”œâ”€â”€ db
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ config.py
    â”‚   â”‚   â”œâ”€â”€ database.py
    â”‚   â”‚   â””â”€â”€ migration_manager.py
    â”‚   â”œâ”€â”€ etl
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ base_processor.py
    â”‚   â”‚   â”œâ”€â”€ chembl_drugs.py
    â”‚   â”‚   â”œâ”€â”€ clinical_trials.py
    â”‚   â”‚   â”œâ”€â”€ drug_repurposing_hub.py
    â”‚   â”‚   â”œâ”€â”€ drugs.py
    â”‚   â”‚   â”œâ”€â”€ evidence_scoring.py
    â”‚   â”‚   â”œâ”€â”€ go_terms.py
    â”‚   â”‚   â”œâ”€â”€ id_enrichment.py
    â”‚   â”‚   â”œâ”€â”€ pathways.py
    â”‚   â”‚   â”œâ”€â”€ pharmgkb_annotations.py
    â”‚   â”‚   â”œâ”€â”€ products.py
    â”‚   â”‚   â”œâ”€â”€ publications.py
    â”‚   â”‚   â”œâ”€â”€ scoring_analytics.py
    â”‚   â”‚   â””â”€â”€ transcript.py
    â”‚   â”œâ”€â”€ migrations
    â”‚   â”‚   â””â”€â”€ remove_migration_files.py
    â”‚   â””â”€â”€ utils
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ download.py
    â”‚       â”œâ”€â”€ gene_matcher.py
    â”‚       â”œâ”€â”€ logging.py
    â”‚       â”œâ”€â”€ pandas_helpers.py
    â”‚       â”œâ”€â”€ progress.py
    â”‚       â”œâ”€â”€ publication_types.py
    â”‚       â”œâ”€â”€ publication_utils.py
    â”‚       â””â”€â”€ validation.py
    â””â”€â”€ tests
        â”œâ”€â”€ conftest.py
        â”œâ”€â”€ test_patient_copy.py
        â”œâ”€â”€ db
        â”‚   â””â”€â”€ test_schema_migrations.py
        â”œâ”€â”€ etl
        â”‚   â”œâ”€â”€ test_drugs.py
        â”‚   â”œâ”€â”€ test_go_terms.py
        â”‚   â”œâ”€â”€ test_integration.py
        â”‚   â”œâ”€â”€ test_integration_products.py
        â”‚   â”œâ”€â”€ test_products.py
        â”‚   â”œâ”€â”€ test_publications.py
        â”‚   â””â”€â”€ test_transcript.py
        â”œâ”€â”€ test_api
        â”‚   â””â”€â”€ test_basic.py
        â”œâ”€â”€ test_db
        â”‚   â””â”€â”€ test_basic.py
        â”œâ”€â”€ test_etl
        â”‚   â””â”€â”€ test_basic.py
        â””â”€â”€ utils
            â”œâ”€â”€ test_publication_utils.py
            â””â”€â”€ test_validation.py

```



## Project Statistics

- Total Files: 73
- Text Files: 73
- Binary Files: 0
- Repository Size: 1.2 MB
- Current Branch: dev
- Most Common File Types:
  - .py: 58
  - .md: 15

## File Contents

### filepath CLAUDE.md

````markdown
# CLAUDE.md [lines:3]
## Project Overview [lines:9]
## Development Environment [lines:1]
### Dependency Management [lines:4]
### Python Version [lines:4]
## Common Development Commands [lines:1]
### Environment Setup [lines:1]
# Install dependencies [lines:2]
# Activate environment [lines:2]
# Install new dependency [lines:3]
### Testing [lines:1]
# Run all tests [lines:2]
# Run specific test file [lines:2]
# Run with coverage [lines:2]
# Run integration tests only [lines:2]
# Run unit tests only   [lines:3]
### Code Quality [lines:1]
# Format code [lines:2]
# Sort imports [lines:2]
# Type checking [lines:2]
# Lint code [lines:3]
### Database Management [lines:1]
# Database operations via manage_db.py [lines:4]
# Initialize test database [lines:3]
### ETL Pipeline [lines:1]
# Run complete ETL pipeline [lines:2]
# Run specific modules [lines:2]
# Limit processing for testing [lines:2]
# Run with debug output [lines:3]
## Architecture [lines:1]
### ETL Module Structure [lines:10]
### Base Classes [lines:4]
### Database Schema [lines:4]
## Code Style Guidelines [lines:1]
### From Copilot Instructions [lines:9]
### Logging Standards [lines:1]
# Console logging with rich formatting [lines:3]
# Progress bars with tqdm [lines:4]
# File logging with rotation [lines:4]
### Error Handling [lines:4]
## Database Operations [lines:1]
### Connection Management [lines:3]
# Get database manager instance [lines:2]
# Use context manager for transactions [lines:4]
### Environment Variables [lines:6]
## Testing Guidelines [lines:1]
### Test Organization [lines:5]
### Database Testing [lines:4]
## Patient Copy Functionality [lines:1]
### Creating Patient-Specific Databases [lines:3]
# Create patient copy with transcriptome data [lines:4]
# Validate CSV without making changes [lines:6]
### CSV Requirements [lines:5]
### Workflow [lines:5]
## Important Notes [lines:1]
### When Working on ETL Modules [lines:5]
### Performance Considerations [lines:5]
### Error Recovery [lines:3]
````

### filepath config/etl_sequence.py

```python
def validate_sequence(modules: List[str]) -> bool: [lines:24]
def get_optimal_sequence(requested_modules: Optional[List[str]] = None) -> List[str]: [lines:22]
def _add_dependencies_recursive(module: str, all_modules: Set[str]) -> None: [lines:13]
```

### filepath config/settings.py

```python
def get_config() -> Dict[str, Any]: [lines:3]
```

### filepath docs/api.md

````markdown
# API Reference Documentation [lines:1]
## Overview [lines:1]
## Publications Module [lines:1]
### PublicationsProcessor [lines:4]
# Initialize with configuration [lines:2]
# Create a reference [lines:6]
# Add to transcript [lines:6]
# Run enrichment pipeline [lines:3]
### Publication Utilities [lines:9]
# Extract PMIDs [lines:3]
# Format citation [lines:2]
# Merge references [lines:3]
## Pathway Module [lines:1]
### PathwayProcessor [lines:4]
# Initialize with configuration [lines:2]
# Run full pipeline (includes publication extraction) [lines:2]
# Extract publication references from pathway evidence [lines:3]
### Pathway Publication Extraction [lines:2]
# Run extraction script [lines:3]
## GO Terms Module [lines:1]
### GOTermProcessor [lines:4]
# Initialize with configuration [lines:2]
# Run full pipeline [lines:2]
# Extract publications from GO evidence codes [lines:3]
### GO Publication Extraction [lines:2]
# Run extraction script [lines:6]
````

### filepath docs/architecture.md

````markdown
# MEDIABASE Architecture Documentation [lines:1]
## Overview [lines:3]
## System Architecture [lines:1]
### High-Level Components [lines:27]
## Enhanced Publication Reference Architecture [lines:1]
### Publication Enhancement System Components [lines:1]
#### 1. Multi-Source Publication Extraction [lines:24]
#### 2. Publication Quality Scoring System [lines:18]
## ETL Pipeline Architecture [lines:1]
### Enhanced ETL Processors [lines:1]
#### 1. Base Processor Pattern [lines:12]
#### 2. Publication-Enhanced Processors [lines:33]
### Publication Reference Data Flow [lines:39]
## Database Architecture [lines:1]
### Enhanced Schema Design [lines:1]
#### Core Table: `cancer_transcript_base` [lines:5]
#### Publication Reference Schema [lines:23]
#### Clinical Trials Schema [lines:25]
### Database Indexes for Publication Queries [lines:8]
## Publication Quality Scoring System [lines:1]
### Multi-Factor Impact Scoring Algorithm [lines:1]
#### Impact Score Components (0-100 scale) [lines:7]
#### Context-Aware Relevance Assessment [lines:6]
#### Quality Tier Classification [lines:6]
### Journal Impact Factor Database [lines:8]
## API and Query Architecture [lines:1]
### Publication-Enhanced Query Capabilities [lines:1]
#### New Query Types [lines:5]
#### Performance Optimizations [lines:5]
## Patient Copy Architecture [lines:1]
### Database Duplication for Patient Analysis [lines:5]
## Error Handling and Monitoring [lines:1]
### Publication-Specific Error Handling [lines:5]
### Monitoring and Logging [lines:5]
## Scalability and Performance [lines:1]
### Publication System Scalability [lines:5]
### Performance Metrics [lines:5]
## Future Architecture Considerations [lines:1]
### Planned Enhancements [lines:5]
### Integration Points [lines:5]
## Security and Data Privacy [lines:1]
### Publication Data Security [lines:6]
````

### filepath docs/current_etl_issues.md

````markdown
# Current ETL Pipeline Issues & Fixes [lines:1]
## Module-by-Module Analysis [lines:1]
### 1. Transcript Module (`src/etl/transcript.py`) [lines:1]
#### Current Issues [lines:1]
# PROBLEM: Limited ID extraction from GTF [lines:7]
#### Missing GTF Attributes [lines:7]
#### Immediate Fix [lines:1]
# Enhanced ID extraction [lines:3]
# Extract all available IDs from GTF [lines:17]
### 2. ID Enrichment Module (`src/etl/id_enrichment.py`) [lines:1]
#### Current Issues [lines:3]
# Current approach is UniProt-only [lines:8]
# Current matching is case-sensitive only [lines:9]
#### Immediate Fixes [lines:53]
### 3. GO Terms Module (`src/etl/go_terms.py`) [lines:1]
#### Current Issues [lines:3]
# Current approach in go_terms.py [lines:1]
# This function is too simplistic [lines:8]
#### Immediate Fixes [lines:53]
### 4. Drugs Module (`src/etl/drugs.py`) [lines:1]
#### Current Issues [lines:6]
# Current drug processing lacks clinical evidence [lines:9]
#### Immediate Fixes [lines:38]
### 5. Publications Module (`src/etl/publications.py`) [lines:1]
#### Current Issues [lines:3]
# Current publications module is isolated [lines:12]
#### Immediate Fixes [lines:40]
## Recommended Implementation Order [lines:1]
### Phase 1: Critical ID Mapping Fix (Week 1) [lines:5]
### Phase 2: Evidence Integration (Week 2)   [lines:5]
### Phase 3: Cross-Module Integration (Week 3) [lines:5]
## Quick Wins (Can Implement Today) [lines:1]
### 1. Fix Transcript ID Extraction [lines:1]
# Update transcript.py to extract more GTF attributes [lines:0]
# Add protein_id, transcript_support_level, tags [lines:2]
### 2. Add NCBI Gene2Ensembl Download [lines:1]
# Add download_gene2ensembl method to id_enrichment.py [lines:0]
# ~10 minutes to implement [lines:2]
### 3. Enhance Gene Matching [lines:1]
# Improve case-insensitive matching in id_enrichment.py [lines:0]
# Add alias matching capability [lines:2]
### 4. Move ID Enrichment Earlier [lines:1]
# Update run_etl.py module order [lines:0]
# Put id_enrichment before go_terms [lines:3]
````

### filepath docs/data_source_schemas.md

````markdown
# Data Source Schemas and Integration Strategy [lines:1]
## Current Data Sources Analysis [lines:1]
### 1. GENCODE GTF (Transcripts Module) [lines:1]
#### Source Details [lines:6]
#### Sample Record [lines:4]
#### Integration Strategy [lines:5]
#### Enhanced Schema Extraction [lines:15]
### 2. UniProt ID Mapping (ID Enrichment Module) [lines:1]
#### Source Details [lines:6]
#### Sample Records [lines:10]
#### Integration Strategy [lines:4]
### 3. Gene Ontology OBO + GOA (GO Terms Module) [lines:1]
#### GO OBO Source [lines:4]
#### Sample GO OBO Record [lines:9]
#### GOA Source   [lines:4]
#### Sample GOA Record [lines:4]
#### Integration Issues [lines:4]
### 4. Reactome Pathways (Pathways Module) [lines:1]
#### Source Details [lines:4]
#### Sample Record [lines:6]
#### Integration Issues [lines:4]
### 5. DrugCentral (Drugs Module) [lines:1]
#### Source Details [lines:4]
#### Sample Records (from SQL dump) [lines:6]
#### Integration Issues [lines:4]
## Missing Critical Data Sources [lines:1]
### 1. NCBI Gene2Ensembl (PRIORITY 1) [lines:1]
#### Why Critical [lines:4]
#### Source Details [lines:5]
#### Sample Record [lines:6]
#### Integration Strategy [lines:1]
# This would fix 90% of our ID mapping issues [lines:17]
### 2. HGNC Complete Dataset (PRIORITY 1) [lines:1]
#### Why Critical [lines:4]
#### Source Details [lines:4]
#### Sample Record [lines:7]
#### Integration Strategy [lines:15]
### 3. ChEMBL Target Data (PRIORITY 1) [lines:1]
#### Why Better Than DrugCentral [lines:5]
#### Source Details [lines:4]
#### Sample API Response [lines:19]
### 4. ClinicalTrials.gov API (PRIORITY 2) [lines:1]
#### Why Critical for Clinical Evidence [lines:4]
#### API Details [lines:4]
#### Sample API Response [lines:25]
#### Integration Strategy [lines:20]
## Recommended Schema Updates for README [lines:4]
## Data Sources and Integration [lines:1]
### Primary Sources [lines:12]
### Integration Strategy [lines:1]
#### Phase 1: ID Resolution [lines:5]
#### Phase 2: Functional Annotation   [lines:3]
#### Phase 3: Clinical Data [lines:3]
### Sample Integrated Record [lines:32]
## ðŸš€ NEW: Publication Reference Extraction Schemas [lines:1]
### Publication Enhancement System (Phase 1-4 Implementation) [lines:1]
#### Phase 1: Multi-Source PMID Extraction [lines:3]
# Enhanced GO evidence code processing [lines:17]
# Fixed column mapping for URL-based extraction [lines:17]
# Clinical and variant annotation PMIDs [lines:26]
# Support for 10+ identifier types [lines:17]
#### Phase 2: ChEMBL Publications Integration [lines:46]
#### Phase 3: ClinicalTrials.gov API Integration [lines:74]
#### Phase 4: Publication Quality Scoring System [lines:124]
### Database Integration Schema [lines:48]
### Publication Enhancement Results [lines:16]
````

### filepath docs/deployment.md

````markdown
# Deployment Documentation [lines:1]
## Overview [lines:2]
````

### filepath docs/etl_action_plan.md

````markdown
# ETL Pipeline Action Plan - Immediate Steps [lines:1]
## Executive Summary [lines:9]
## Immediate Impact Fixes (This Week) [lines:1]
### ðŸš¨ Priority 1: Fix ID Mapping (Day 1-2) [lines:1]
#### Problem [lines:2]
#### Quick Fix [lines:1]
# 1. Add NCBI Gene2Ensembl download to id_enrichment.py [lines:2]
# 2. Move id_enrichment to run BEFORE go_terms in run_etl.py [lines:0]
# Current: transcripts â†’ id_enrichment â†’ go_terms   [lines:0]
# Fixed:   transcripts â†’ id_enrichment â†’ go_terms (with better IDs) [lines:2]
#### Implementation [lines:1]
# Add to src/etl/id_enrichment.py [lines:21]
#### Expected Impact [lines:4]
### ðŸš¨ Priority 2: Enhance Transcript ID Extraction (Day 1) [lines:1]
#### Problem [lines:2]
#### Current Code [lines:1]
# Only extracts 2 ID types! [lines:6]
#### Enhanced Code [lines:1]
# Extract ALL available GTF attributes [lines:16]
#### Expected Impact [lines:4]
### ðŸš¨ Priority 3: Add ChEMBL Integration (Day 3-4) [lines:1]
#### Problem [lines:2]
#### Quick Win: ChEMBL API Integration [lines:1]
# Add to src/etl/chembl_drugs.py (enhance existing) [lines:23]
#### Expected Impact [lines:4]
## Medium-Term Improvements (Week 2-3) [lines:1]
### ðŸŽ¯ Goal 1: Clinical Evidence Integration [lines:1]
#### Add ClinicalTrials.gov API [lines:1]
# New module: src/etl/clinical_trials.py [lines:19]
### ðŸŽ¯ Goal 2: Evidence Scoring System [lines:1]
#### Cross-Module Evidence Integration [lines:1]
# New module: src/etl/evidence_integration.py [lines:33]
### ðŸŽ¯ Goal 3: Enhanced SOTA Analysis [lines:1]
#### Update SOTA Analysis to Use Evidence Scores [lines:1]
# Update scripts/run_sota_analysis.py [lines:29]
## Implementation Timeline [lines:1]
### Week 1: Foundation Fixes [lines:6]
### Week 2: Evidence Integration [lines:4]
### Week 3: Integration & Testing [lines:4]
## Expected Outcomes [lines:1]
### Quantitative Improvements [lines:5]
### Qualitative Improvements [lines:5]
## Quick Start Commands [lines:2]
# 1. Backup current state [lines:2]
# 2. Implement Priority 1 fixes [lines:4]
# 3. Test with limited dataset [lines:2]
# 4. Run SOTA analysis to validate improvements [lines:4]
````

### filepath docs/etl_improvement_plan.md

````markdown
# ETL Pipeline Improvement Plan [lines:1]
## Current State Analysis [lines:1]
### Critical Issues Identified [lines:7]
## Recommended Data Sources & Schema [lines:1]
### 1. Comprehensive ID Mapping Sources [lines:1]
#### NCBI Gene2Ensembl (PRIORITY 1) [lines:9]
#### HGNC Complete Dataset (PRIORITY 1)   [lines:8]
#### RefSeq Complete (PRIORITY 2) [lines:3]
### 2. Enhanced Evidence Sources [lines:1]
#### ChEMBL Database (PRIORITY 1) [lines:15]
#### ClinicalTrials.gov API (PRIORITY 1) [lines:15]
#### PubMed Central Cancer Collection (PRIORITY 2) [lines:4]
### 3. Cancer-Specific Sources [lines:1]
#### COSMIC Database (PRIORITY 2) [lines:8]
#### TCGA Pan-Cancer Atlas (PRIORITY 3)   [lines:3]
## Improved Pipeline Sequence [lines:1]
### Phase 1: Foundation & ID Mapping [lines:8]
### Phase 2: Functional Enrichment   [lines:4]
### Phase 3: Clinical & Drug Data [lines:4]
### Phase 4: Evidence & References [lines:4]
## Implementation Priority [lines:1]
### Week 1: Critical ID Mapping [lines:5]
### Week 2: Enhanced Evidence [lines:4]
### Week 3: Cross-Module Integration [lines:4]
### Week 4: Documentation & Validation [lines:5]
## Success Metrics [lines:1]
### ID Mapping Improvement [lines:3]
### Evidence Quality [lines:3]
### Clinical Utility [lines:3]
## Technical Implementation Notes [lines:1]
### New Module Template [lines:20]
### Evidence Integration Pattern [lines:13]
## Schema Documentation Requirements [lines:3]
### Data Source Template [lines:1]
#### [Source Name]
````

### filepath docs/evidence_scoring.md

````markdown
# Evidence Scoring Framework for MEDIABASE [lines:1]
## Overview [lines:3]
## Motivation [lines:14]
## Scoring Architecture [lines:1]
### Evidence Types and Weighting [lines:3]
#### 1. Clinical Evidence (0-30 points) [lines:27]
#### 2. Mechanistic Evidence (0-25 points) [lines:6]
#### 3. Publication Evidence (0-20 points) [lines:10]
#### 4. Genomic Evidence (0-15 points) [lines:6]
#### 5. Safety Evidence (0-10 points) [lines:6]
### Use Case Optimization [lines:3]
#### Drug Repurposing (Clinical Safety Focus) [lines:8]
#### Biomarker Discovery (Genomic Focus) [lines:8]
#### Pathway Analysis (Mechanistic Focus) [lines:8]
#### Therapeutic Targeting (Balanced Approach) [lines:8]
## Statistical Framework [lines:1]
### Confidence Intervals [lines:4]
# Uncertainty calculation [lines:6]
### Evidence Quality Metrics [lines:12]
### Source Reliability Weights [lines:16]
## Implementation Details [lines:1]
### Core Components [lines:1]
#### 1. EvidenceScoringProcessor [lines:6]
#### 2. Evidence Score Classes [lines:5]
#### 3. Scoring Methods [lines:7]
### Database Schema [lines:34]
## Usage Examples [lines:1]
### Command Line Interface [lines:2]
# Test scoring with limited records [lines:2]
# Run full scoring for all genes [lines:2]
# View results [lines:3]
### Database Queries [lines:31]
### Programmatic Access [lines:4]
# Initialize processor [lines:3]
# Calculate scores for specific gene data [lines:6]
# Get individual evidence scores [lines:3]
# Calculate composite score for drug repurposing [lines:8]
## Interpretation Guidelines [lines:1]
### Score Ranges [lines:16]
### Evidence Quality Thresholds [lines:6]
### Confidence Interval Width [lines:5]
## Validation and Quality Control [lines:1]
### Cross-Validation [lines:8]
### Quality Metrics [lines:6]
### Limitations and Considerations [lines:7]
## Future Enhancements [lines:1]
### Planned Improvements [lines:7]
### Data Source Expansion [lines:7]
### Advanced Analytics [lines:6]
## Technical Reference [lines:1]
### Configuration Options [lines:18]
### Performance Considerations [lines:6]
### Error Handling [lines:6]
## Contributing [lines:1]
### Adding New Evidence Types [lines:7]
### Modifying Scoring Algorithms [lines:7]
### Data Source Integration [lines:8]
````

### filepath docs/evidence_scoring_framework.md

````markdown
# Comprehensive Evidence Scoring Framework for MEDIABASE [lines:1]
## Overview [lines:3]
## Table of Contents [lines:10]
## Framework Architecture [lines:1]
### Core Components [lines:46]
### Data Flow [lines:9]
## Evidence Types and Sources [lines:1]
### 1. Clinical Evidence (0-30 points) [lines:27]
### 2. Mechanistic Evidence (0-25 points) [lines:27]
### 3. Publication Support (0-20 points) [lines:27]
### 4. Genomic Evidence (0-15 points) [lines:27]
### 5. Safety Evidence (0-10 points) [lines:27]
## Scoring Methodology [lines:1]
### Component Score Calculation [lines:3]
#### Clinical Evidence Scoring [lines:9]
#### Mechanistic Evidence Scoring [lines:9]
### Overall Score Calculation [lines:10]
### Confidence Interval Calculation [lines:21]
## Use Case Optimization [lines:1]
### Drug Repurposing (Clinical Focus) [lines:26]
### Biomarker Discovery (Genomic Focus) [lines:10]
### Pathway Analysis (Mechanistic Focus) [lines:10]
### Therapeutic Targeting (Balanced Approach) [lines:10]
## Quality Metrics [lines:1]
### Evidence Quality Assessment [lines:13]
### Age Decay Factors [lines:9]
## Implementation Guide [lines:1]
### 1. Database Schema Updates [lines:7]
### 2. Configuration [lines:16]
### 3. Running Evidence Scoring [lines:2]
# Score all genes [lines:2]
# Score specific genes [lines:2]
# Score for specific use case [lines:2]
# Force recalculation [lines:2]
# Validate results [lines:2]
# Export results [lines:3]
### 4. Integration with ETL Pipeline [lines:6]
# Initialize processor [lines:3]
# Run scoring for all genes [lines:2]
# Score specific gene [lines:3]
## API Reference [lines:1]
### Core Classes [lines:1]
#### EvidenceScoringProcessor [lines:7]
#### EvidenceItem [lines:9]
#### EvidenceScore [lines:9]
### Database Schema [lines:1]
#### evidence_scoring_metadata Table [lines:18]
#### Evidence Quality Metrics [lines:13]
### Materialized Views [lines:1]
#### High-Confidence Drug Targets [lines:7]
#### Drug Repurposing Candidates [lines:6]
#### Biomarker Discovery Targets [lines:6]
### Utility Functions [lines:1]
#### Get Gene Evidence Summary [lines:4]
#### Compare Drugs for Gene [lines:4]
#### Refresh Analytics [lines:4]
## Validation and Analytics [lines:1]
### Scoring Analytics Module [lines:6]
# Initialize analytics processor [lines:2]
# Analyze individual gene [lines:2]
# Comparative analysis across genes [lines:2]
# Export comprehensive report [lines:3]
### Quality Validation [lines:14]
### Performance Monitoring [lines:8]
## Best Practices [lines:1]
### 1. Data Quality Assurance [lines:6]
### 2. Score Interpretation [lines:6]
### 3. Use Case Selection [lines:6]
### 4. Continuous Improvement [lines:6]
## Troubleshooting [lines:1]
### Common Issues [lines:19]
### Debugging Tools [lines:2]
# Debug evidence extraction [lines:4]
# Debug component scoring [lines:5]
## Future Enhancements [lines:1]
### Planned Features [lines:21]
### Research Applications [lines:12]
````

### filepath docs/patient_copy_guide.md

````markdown
# Patient Copy Guide [lines:3]
## Overview [lines:7]
## Quick Start [lines:1]
### Basic Usage [lines:2]
# Create patient copy with fold-change data [lines:4]
# Dry run to validate CSV without making changes [lines:6]
### Advanced Usage [lines:2]
# Use specific source database [lines:5]
# Enable debug logging [lines:6]
## CSV File Requirements [lines:1]
### Required Columns [lines:11]
### CSV Format Example [lines:10]
### Supported Data Types [lines:9]
### Column Mapping [lines:19]
## Database Structure [lines:1]
### Target Database [lines:5]
### Data Updates [lines:11]
### Data Preservation [lines:9]
## Environment Setup [lines:1]
### Required Environment Variables [lines:2]
# Database connection [lines:5]
# Source database (optional, defaults to 'mediabase') [lines:3]
### Dependencies [lines:6]
## Validation and Error Handling [lines:1]
### Pre-flight Checks [lines:8]
### Error Recovery [lines:6]
### Validation Output [lines:24]
## Best Practices [lines:1]
### Data Preparation [lines:6]
### Database Management [lines:6]
### Performance Optimization [lines:5]
## Troubleshooting [lines:1]
### Common Issues [lines:31]
### Debug Mode [lines:10]
### Manual Cleanup [lines:8]
## Integration with Analysis Workflows [lines:1]
### Next Steps After Patient Copy [lines:12]
### Example Queries [lines:37]
## Security Considerations [lines:6]
## Support [lines:6]
````

### filepath docs/postgres_setup_guide.md

````markdown
# PostgreSQL Setup Guide [lines:1]
## Prerequisites [lines:5]
## Database Management [lines:3]
## Container Setup [lines:20]
## Database Management Scripts [lines:7]
### Usage [lines:16]
## Environment Configuration [lines:11]
## Verification [lines:7]
## Container Management [lines:21]
## Backup and Restore [lines:11]
## Troubleshooting [lines:14]
## Schema Management [lines:1]
### Version 0.1.4 Features [lines:13]
### Upgrading to v0.1.4 [lines:34]
### Maintenance [lines:27]
````

### filepath docs/publication_enhancement_plan.md

````markdown
# MEDIABASE Publication Reference Enhancement Plan [lines:1]
## Executive Summary [lines:3]
## Current State Analysis [lines:1]
### âœ… **Strong Foundation** [lines:4]
### âŒ **Critical Issues** [lines:5]
## Data Source Publication Audit [lines:1]
### 1. **PharmGKB** (ðŸŸ¡ Partial Implementation) [lines:8]
### 2. **GO Terms** (ðŸ”´ Major Gap) [lines:12]
### 3. **DrugCentral** (ðŸ”´ Critical Issue) [lines:8]
### 4. **ChEMBL** (ðŸ”´ Missing Implementation) [lines:7]
### 5. **Reactome Pathways** (ðŸ”´ Not Implemented) [lines:6]
## Root Cause Analysis [lines:1]
### 1. **GO Terms PMID Extraction Failure** [lines:7]
# Evidence code is processed but PMIDs are ignored [lines:1]
# Missing: PMID extraction from evidence code [lines:4]
# Extract PMIDs from evidence codes [lines:6]
### 2. **DrugCentral Reference Column Error** [lines:19]
### 3. **PharmGKB PMID Processing Gap** [lines:5]
### 4. **PMID Pattern Matching Limitations** [lines:15]
## Enhancement Plan [lines:1]
### **âœ… Phase 1: Critical Fixes (COMPLETED)** [lines:1]
#### âœ… 1.1 Fix GO Evidence Code PMID Extraction [lines:22]
#### âœ… 1.2 Enhanced PMID Pattern Matching [lines:12]
#### âœ… 1.3 DrugCentral Reference Column Fix [lines:25]
### **Phase 2: ChEMBL Publications Integration (Week 2)** [lines:1]
#### 2.1 ChEMBL Publications Table Population [lines:26]
#### 2.2 Clinical Trial Literature Extraction [lines:20]
### **Phase 3: Advanced Clinical Trial Integration (Week 3-4)** [lines:1]
#### 3.1 ClinicalTrials.gov API Integration [lines:34]
#### 3.2 Drug Trial Reference Integration [lines:22]
### **Phase 4: Publication Quality Enhancement (Week 5-6)** [lines:1]
#### 4.1 Citation Impact Analysis [lines:30]
#### 4.2 Evidence Strength Assessment [lines:30]
## Implementation Priority Matrix [lines:10]
## âœ… **COMPLETED PHASE 1 RESULTS** [lines:1]
### **âœ… Immediate Fixes Implemented** [lines:6]
### **âœ… Technical Improvements** [lines:7]
## Expected Outcomes [lines:1]
### **âœ… Immediate (Phase 1) - COMPLETED** [lines:5]
### **âœ… Short-term (Phase 2-3) - COMPLETED** [lines:5]
### **âœ… Long-term (Phase 4) - COMPLETED** [lines:5]
## Success Metrics [lines:7]
## âœ… **FINAL IMPLEMENTATION STATUS: ALL PHASES COMPLETED & TESTED** [lines:1]
### **ðŸ“Š Comprehensive Achievement Summary** [lines:3]
#### **Phase 1: Critical Fixes (100% Complete âœ… Tested)** [lines:5]
#### **Phase 2: ChEMBL Publications Integration (100% Complete âœ… Tested)** [lines:5]
#### **Phase 3: ClinicalTrials.gov API Integration (100% Complete âœ… Tested)** [lines:5]
#### **Phase 4: Publication Quality Scoring (100% Complete âœ… Tested)** [lines:6]
### **ðŸ§ª COMPREHENSIVE TEST VALIDATION COMPLETED** [lines:12]
### **ðŸŽ¯ Final Results Achieved & Validated** [lines:16]
### **ðŸš€ Validated Impact for Cancer Research** [lines:12]
````

### filepath docs/publication_references.md

````markdown
# Publication References Guide - Enhanced System [lines:3]
## ðŸš€ Enhanced System Overview [lines:3]
### Key Enhancements: [lines:8]
## Enhanced Reference Structure [lines:38]
## Enhanced Source Categories [lines:11]
### NEW: Clinical Trials Category [lines:5]
## ðŸš€ Enhanced Extraction Process [lines:1]
### Phase 1: Multi-Source PMID Extraction [lines:1]
#### GO Term References (ENHANCED) [lines:16]
# Automatically extracts 10,000+ GO literature references [lines:2]
#### DrugCentral References (ENHANCED) [lines:15]
# Automatically extracts PMIDs from DrugCentral URL columns [lines:2]
#### PharmGKB References (ENHANCED) [lines:14]
# Automatically integrates PharmGKB PMIDs into source_references [lines:2]
#### Enhanced Pattern Matching (NEW) [lines:9]
### Phase 2: ChEMBL Publications Integration (NEW) [lines:1]
#### ChEMBL Publications Table [lines:10]
# Populates ChEMBL publications and extracts drug literature [lines:2]
### Phase 3: ClinicalTrials.gov API Integration (NEW) [lines:1]
#### Live API Integration [lines:16]
# Searches ClinicalTrials.gov and extracts trial publications [lines:2]
### Phase 4: Publication Quality Scoring (NEW) [lines:1]
#### Multi-Factor Impact Scoring [lines:17]
# Applies quality scoring to all extracted publications [lines:2]
### Metadata Enrichment [lines:8]
## Working with References [lines:1]
### TypedDict Structure [lines:18]
### Creating References [lines:4]
# Create a reference with minimal information [lines:7]
# Add to a transcript [lines:7]
### Extracting PMIDs from Text [lines:4]
# Extract a single PMID [lines:2]
# Extract all PMIDs [lines:3]
### Formatting Citations [lines:6]
# Smith J et al. Gene X regulates pathway Y. Nature Genetics, 2020. PMID: 12345678 [lines:2]
## Database Schema [lines:17]
## Querying References [lines:41]
## Performance Considerations [lines:6]
````

### filepath scripts/create_patient_copy.py

```python
class PatientCopyError(Exception): [lines:3]
class CSVValidationError(PatientCopyError): [lines:3]
class DatabaseCopyError(PatientCopyError): [lines:3]
class FoldChangeUpdateError(PatientCopyError): [lines:3]
class PatientDatabaseCreator: [lines:438]
def main(): [lines:108]
def __init__(self, patient_id: str, csv_file: Path, source_db_config: Dict[str, Any]): [lines:29]
def validate_csv_file(self) -> None: [lines:35]
def _display_csv_info(self) -> None: [lines:16]
def _find_column_mapping(self, available_columns: Set[str]) -> Dict[str, str]: [lines:22]
def _interactive_column_mapping(self, available_columns: Set[str]) -> None: [lines:21]
def _get_column_description(self, column: str) -> str: [lines:14]
def _validate_mapped_columns(self) -> None: [lines:43]
def create_patient_database(self) -> None: [lines:23]
def _create_target_database(self, source_db: DatabaseManager) -> None: [lines:35]
def _copy_database_content(self, source_db: DatabaseManager) -> None: [lines:36]
def update_fold_changes(self) -> None: [lines:86]
def _log_update_statistics(self) -> None: [lines:19]
def validate_result(self) -> None: [lines:44]
```

### filepath scripts/manage_db.py

```python
class DatabaseMenu: [lines:71]
def load_config() -> Dict[str, Any]: [lines:20]
def main(): [lines:28]
def __init__(self, db_manager): [lines:9]
def display_menu(self): [lines:7]
def check_status(self): [lines:4]
def reset_database(self): [lines:8]
def backup_database(self): [lines:8]
def restore_database(self): [lines:11]
def exit_program(self): [lines:4]
def run(self): [lines:10]
```

### filepath scripts/manage_patient_databases.py

```python
class PatientDatabaseManager: [lines:409]
def main(): [lines:127]
def __init__(self, db_config: Dict[str, Any]): [lines:9]
def list_patient_databases(self, show_details: bool = True) -> List[Dict[str, Any]]: [lines:68]
def _get_database_details(self, db_name: str) -> Dict[str, Any]: [lines:64]
def display_patient_databases(self, patient_dbs: List[Dict[str, Any]]) -> None: [lines:49]
def get_database_info(self, patient_id: str) -> Optional[Dict[str, Any]]: [lines:16]
def display_database_info(self, patient_id: str) -> None: [lines:45]
def _display_sample_transcripts(self, db_name: str, limit: int = 10) -> None: [lines:41]
def delete_patient_database(self, patient_id: str, force: bool = False) -> bool: [lines:60]
def cleanup_old_databases(self, days_old: int, dry_run: bool = False) -> int: [lines:46]
```

### filepath scripts/run_chembl_enrichment.py

```python
def parse_args() -> argparse.Namespace: [lines:63]
def main() -> None: [lines:44]
```

### filepath scripts/run_etl.py

```python
def get_config() -> Dict[str, Any]: [lines:20]
def run_module( module_name: str, config: Dict[str, Any], limit_transcripts: Optional[int] = None, reset_db: bool = False ) -> bool: [lines:105]
def run_pipeline( config: Dict[str, Any], modules: Optional[List[str]] = None, limit_transcripts: Optional[int] = None, reset_db: bool = False ) -> None: [lines:83]
def get_modules_to_run(args) -> List[str]: [lines:35]
def parse_args() -> argparse.Namespace: [lines:73]
def main() -> int:  # Change return type to int for clarity """Main entry point for ETL pipeline.  Returns: [lines:114]
```

### filepath scripts/run_evidence_scoring.py

```python
def load_config() -> Dict[str, Any]: [lines:20]
def display_scoring_results(stats: Dict[str, Any]) -> None: [lines:42]
def test_evidence_scoring(limit_records: int = 10) -> None: [lines:43]
def run_full_evidence_scoring() -> None: [lines:43]
def main(): [lines:31]
```

### filepath scripts/run_sota_analysis.py

```python
class SOTAAnalyzer: [lines:742]
def main(): [lines:65]
def __init__(self, db_config: Dict[str, Any]): [lines:5]
def get_all_transcripts(self, patient_db: Optional[str] = None) -> List[Dict]: [lines:35]
def analyze_drug_gene_interactions(self, transcripts: List[Dict]) -> Dict[str, Any]: [lines:63]
def analyze_pathway_enrichment(self, transcripts: List[Dict]) -> Dict[str, Any]: [lines:68]
def analyze_functional_classification(self, transcripts: List[Dict]) -> Dict[str, Any]: [lines:68]
def analyze_chromosomal_distribution(self, transcripts: List[Dict]) -> Dict[str, Any]: [lines:76]
def analyze_multimodal_integration(self, transcripts: List[Dict]) -> Dict[str, Any]: [lines:87]
def analyze_clinical_biomarkers(self, transcripts: List[Dict]) -> Dict[str, Any]: [lines:96]
def _generate_drug_clinical_summary(self, interactions: List[Dict], high_score: List[Dict]) -> str: [lines:13]
def _generate_pathway_clinical_summary(self, enriched: List[Dict]) -> str: [lines:10]
def _generate_functional_clinical_summary(self, profiles: List[Dict]) -> str: [lines:10]
def _generate_chromosomal_clinical_summary(self, hotspots: List[Dict], all_stats: List[Dict]) -> str: [lines:10]
def _generate_multimodal_clinical_summary(self, profiles: List[Dict]) -> str: [lines:10]
def _generate_biomarker_clinical_summary(self, biomarkers: List[Dict]) -> str: [lines:10]
def run_complete_analysis(self, patient_db: Optional[str] = None) -> Dict[str, Any]: [lines:75]
def _generate_executive_summary(self) -> Dict[str, Any]: [lines:38]
def save_report(self, output_path: Path, format: str = 'json') -> None: [lines:17]
def _generate_text_report(self, output_path: Path) -> None: [lines:31]
```

### filepath scripts/validate_queries.py

```python
def validate_query_syntax(query_name: str, query: str) -> Dict[str, Any]: [lines:59]
def test_query_compatibility() -> Dict[str, Any]: [lines:45]
def main(): [lines:93]
```

### filepath scripts/verify_db_schema.py

```python
def main() -> int: [lines:91]
```

### filepath src/__init__.py

```python

```

### filepath src/api/queries.py

```python

```

### filepath src/config/constants.py

```python

```

### filepath src/db/__init__.py

```python

```

### filepath src/db/config.py

```python
def get_db_config() -> Dict[str, Any]: [lines:21]
```

### filepath src/db/database.py

```python
class DatabaseManager: [lines:1063]
def get_db_manager(config: Dict[str, Any]) -> DatabaseManager: [lines:12]
def __init__(self, config: Dict[str, Any]): [lines:24]
def _register_adapters(self) -> None: [lines:8]
def connect(self, db_name: Optional[str] = None) -> bool: [lines:21]
def close(self) -> None: [lines:8]
def create_database(self) -> bool: [lines:17]
def drop_database(self) -> bool: [lines:28]
def get_current_version(self) -> Optional[str]: [lines:68]
def get_current_schemaversion_number(self) -> Optional[int]: [lines:20]
def migrate_to_version(self, target_version: str) -> bool: [lines:89]
def get_table_stats(self) -> Dict[str, Any]: [lines:31]
def reset(self) -> bool: [lines:71]
def display_status(self) -> None: [lines:21]
def check_db_exists(self) -> bool: [lines:16]
def dump_database(self, output_file: str) -> bool: [lines:45]
def restore_database(self, input_file: str) -> bool: [lines:39]
def check_column_exists(self, table: str, column: str) -> bool: [lines:32]
def print_config(self) -> None: [lines:10]
def ensure_connection(self) -> bool: [lines:48]
def execute_safely(self, query: str, params: Optional[Tuple] = None, commit: bool = True) -> Optional[pg_cursor]: [lines:36]
def get_version_sequence(self) -> List[str]: [lines:10]
def reset_database(self) -> bool: [lines:172]
def apply_full_schema(self) -> bool: [lines:85]
def validate_schema(self) -> bool: [lines:75]
def ensure_schema_version(self, required_version: str) -> bool: [lines:59]
def display_config(self) -> None: [lines:3]
def adapt_dict(dict_value: dict) -> AsIs: [lines:3]
```

### filepath src/db/migration_manager.py

```python
class MigrationManager: [lines:68]
def __init__(self, db_connection: Any) -> None: [lines:7]
def check_version(self) -> str: [lines:16]
def migrate_if_needed(self) -> bool: [lines:16]
def _compare_versions(self, version1: str, version2: str) -> int: [lines:23]
```

### filepath src/etl/__init__.py

```python

```

### filepath src/etl/base_processor.py

```python
class ETLError(Exception): [lines:3]
class DownloadError(ETLError): [lines:3]
class CacheError(ETLError): [lines:3]
class ProcessingError(ETLError): [lines:3]
class DatabaseError(ETLError): [lines:3]
class BaseProcessor: [lines:464]
def __init__(self, config: Dict[str, Any]) -> None: [lines:41]
def _get_cache_key(self, url: str, params: Optional[Dict[str, Any]] = None) -> str: [lines:17]
def _is_cache_valid(self, cache_key: str) -> bool: [lines:31]
def _update_cache_meta(self, cache_key: str, file_path: Path, metadata: Optional[Dict[str, Any]] = None) -> None: [lines:27]
def download_file(self, url: str, file_path: Optional[Path] = None, params: Optional[Dict[str, Any]] = None) -> Path: [lines:62]
def compress_file(self, input_path: Path, output_path: Optional[Path] = None) -> Path: [lines:17]
def decompress_file(self, input_path: Path, output_path: Optional[Path] = None) -> Path: [lines:17]
def ensure_connection(self) -> bool: [lines:11]
def execute_batch(self, query: str, argslist: List[Tuple], page_size: Optional[int] = None) -> None: [lines:30]
def process_in_batches(self, items: List[T], processor: Callable[[List[T]], None], batch_size: Optional[int] = None, desc: str = "Processing batches") -> None: [lines:26]
def get_db_transaction(self): [lines:62]
def check_schema_version(self, required_version: str) -> bool: [lines:36]
def ensure_schema_version(self, required_version: str) -> bool: [lines:24]
def run(self) -> None: [lines:6]
def execute_batch_update(self, query: str, params_list: List[Tuple]) -> int: [lines:32]
class TransactionContext: [lines:47]
def __init__(self, db_manager): [lines:3]
def cursor(self): [lines:14]
def __enter__(self): [lines:13]
def __exit__(self, exc_type, exc_val, exc_tb): [lines:12]
```

### filepath src/etl/chembl_drugs.py

```python
class ChemblDrugProcessor(BaseProcessor): [lines:1808]
def __init__(self, config: Dict[str, Any]) -> None: [lines:39]
def download_chembl_data(self) -> Tuple[Path, Path]: [lines:38]
def extract_chembl_dump(self, dump_file: Path) -> Path: [lines:102]
def process_uniprot_mapping(self, mapping_file: Path) -> Dict[str, Set[str]]: [lines:68]
def create_optimized_tables(self) -> None: [lines:115]
def _process_molecule_dictionary(self, extracted_dir: Path) -> None: [lines:136]
def _process_drug_targets(self, extracted_dir: Path) -> None: [lines:98]
def _process_drug_indications(self, extracted_dir: Path) -> None: [lines:84]
def _process_drug_publications(self, extracted_dir: Path) -> None: [lines:124]
def import_chembl_to_tables(self, extracted_dir: Path) -> None: [lines:50]
def _update_drug_batch(self, updates: List[Tuple[str, List[str], str, str]]) -> None: [lines:57]
def calculate_drug_scores(self) -> None: [lines:203]
def _verify_integration_results(self) -> None: [lines:48]
def _safe_execute(self, query: str, params: Any = None) -> Optional[Any]: [lines:27]
def _safe_commit(self) -> bool: [lines:20]
def _safe_fetch_count(self, table_name: str, schema_name: Optional[str] = None) -> int: [lines:23]
def query_chembl_api(self, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]: [lines:28]
def get_clinical_phase_data(self, gene_symbol: str) -> List[Dict[str, Any]]: [lines:83]
def enhance_existing_drug_data(self) -> None: [lines:74]
def _update_enhanced_drug_data(self, enhanced_drugs: Dict[str, Dict[str, Any]]) -> None: [lines:33]
def _populate_publications_from_docs(self) -> None: [lines:169]
def extract_publication_references(self) -> List[Publication]: [lines:112]
def run(self) -> None: [lines:51]
```

### filepath src/etl/clinical_trials.py

```python
class ClinicalTrialsProcessor(BaseProcessor): [lines:595]
def __init__(self, config: Dict[str, Any]) -> None: [lines:29]
def _make_api_request(self, endpoint: str, params: Dict[str, Any]) -> Dict[str, Any]: [lines:42]
def search_trials_by_gene(self, gene_symbol: str) -> List[Dict[str, Any]]: [lines:59]
def search_studies(self, params: Dict[str, Any]) -> Dict[str, Any]: [lines:10]
def _extract_trial_data(self, study: Dict[str, Any], gene_symbol: str) -> Optional[Dict[str, Any]]: [lines:99]
def _normalize_phase(self, phase: str) -> str: [lines:21]
def _extract_trial_publications(self, derived_section: Dict[str, Any], nct_id: str) -> List[Dict[str, Any]]: [lines:37]
def get_trials_for_genes(self, gene_symbols: List[str]) -> Dict[str, List[Dict[str, Any]]]: [lines:36]
def extract_publication_references(self, gene_trials: Dict[str, List[Dict[str, Any]]]) -> List[Publication]: [lines:61]
def update_transcript_clinical_trial_data(self, gene_trials: Dict[str, List[Dict[str, Any]]]) -> None: [lines:107]
def _is_recent_trial(self, trial: Dict[str, Any]) -> bool: [lines:23]
def run(self) -> None: [lines:57]
```

### filepath src/etl/drug_repurposing_hub.py

```python
class DrugRepurposingHubProcessor(BaseProcessor): [lines:444]
def __init__(self, config: Dict[str, Any]) -> None: [lines:21]
def download_repurposing_hub_data(self) -> Path: [lines:19]
def parse_target_string(self, target_string: str) -> List[str]: [lines:15]
def process_repurposing_hub_data(self, hub_file: Path) -> Dict[str, List[Dict[str, Any]]]: [lines:98]
def update_transcript_drug_data(self, gene_drug_mapping: Dict[str, List[Dict[str, Any]]]) -> None: [lines:103]
def calculate_repurposing_scores(self) -> None: [lines:89]
def generate_repurposing_summary(self) -> None: [lines:45]
def run(self) -> None: [lines:44]
```

### filepath src/etl/drugs.py

```python
class DrugProcessor(BaseProcessor): [lines:1138]
def __init__(self, config: Dict[str, Any]) -> None: [lines:19]
def download_drugcentral(self) -> Path: [lines:19]
def process_drug_targets(self, drug_data_path: Path) -> pd.DataFrame: [lines:100]
def _create_column_mapping(self, header_cols: List[str]) -> Dict[str, str]: [lines:50]
def _clean_drug_data(self, df: pd.DataFrame, column_mapping: Dict[str, str]) -> pd.DataFrame: [lines:26]
def _normalize_drug_data(self, df: pd.DataFrame) -> pd.DataFrame: [lines:31]
def _process_drug_rows(self, df: pd.DataFrame) -> List[Dict[str, Any]]: [lines:53]
def integrate_drugs(self, drug_targets: pd.DataFrame) -> None: [lines:344]
def _update_drug_batch(self, updates: List[Tuple[str, List[str], str, str]]) -> None: [lines:89]
def calculate_drug_scores(self) -> None: [lines:205]
def extract_publication_references(self, drug_references: str) -> List[Publication]: [lines:33]
def extract_drug_references(self, drug_data: Dict[str, Any]) -> List[Publication]: [lines:32]
def run(self) -> None: [lines:64]
def _verify_integration_results(self) -> None: [lines:57]
```

### filepath src/etl/evidence_scoring.py

```python
class EvidenceType(Enum): [lines:7]
class UseCase(Enum): [lines:6]
class EvidenceScore: [lines:8]
class CompositeScore: [lines:8]
class EvidenceScoringProcessor(BaseProcessor): [lines:779]
def __init__(self, config: Dict[str, Any]) -> None: [lines:64]
def calculate_clinical_evidence_score(self, gene_data: Dict[str, Any]) -> EvidenceScore: [lines:144]
def calculate_mechanistic_evidence_score(self, gene_data: Dict[str, Any]) -> EvidenceScore: [lines:72]
def calculate_publication_evidence_score(self, gene_data: Dict[str, Any]) -> EvidenceScore: [lines:59]
def calculate_genomic_evidence_score(self, gene_data: Dict[str, Any]) -> EvidenceScore: [lines:87]
def calculate_safety_evidence_score(self, gene_data: Dict[str, Any]) -> EvidenceScore: [lines:59]
def calculate_composite_score(self, evidence_scores: List[EvidenceScore], use_case: UseCase) -> CompositeScore: [lines:33]
def _calculate_confidence_interval(self, evidence_scores: List[EvidenceScore], weights: Dict[EvidenceType, float], base_score: float) -> Tuple[float, float]: [lines:24]
def _calculate_evidence_quality(self, evidence_scores: List[EvidenceScore]) -> float: [lines:20]
def process_evidence_scoring(self, limit_records: Optional[int] = None) -> Dict[str, Any]: [lines:114]
def _generate_scoring_statistics(self, score_updates: List[Tuple[str, str]]) -> Dict[str, Any]: [lines:40]
def get_required_schema_version(self) -> str: [lines:3]
def run(self): [lines:45]
```

### filepath src/etl/go_terms.py

```python
class GOTerm(TypedDict): [lines:5]
class GOTermProcessor(BaseProcessor): [lines:863]
def integrate_go_terms(self, go_data: Dict[str, Any]) -> None: [lines:130]
def _update_go_batch(self, updates: List[Tuple[str, List[str], str, str]]) -> None: [lines:35]
def __init__(self, config: Dict[str, Any]) -> None: [lines:42]
def download_obo(self) -> Path: [lines:18]
def download_goa(self) -> Path: [lines:18]
def load_go_graph(self, obo_path: Path) -> None: [lines:15]
def get_ancestors(self, term_id: str, aspect: Optional[str] = None) -> Set[str]: [lines:40]
def get_aspect(self, term_id: str) -> Optional[str]: [lines:22]
def _convert_aspect(self, aspect_code: str) -> str: [lines:15]
def _get_valid_genes(self) -> Set[str]: [lines:26]
def process_goa_file(self, goa_path: Path) -> Dict[str, Dict[str, GOTerm]]: [lines:92]
def _display_goa_stats( self, processed: int, matched: int, gene_go_terms: Dict[str, Dict[str, GOTerm]], sample_entries: List[List[str]] ) -> None: [lines:64]
def _extract_special_terms(self, go_terms: Dict[str, GOTerm]) -> Tuple[List[str], List[str]]: [lines:27]
def extract_publication_references(self, go_terms: Dict[str, GOTerm]) -> List[Publication]: [lines:46]
def populate_initial_terms(self) -> None: [lines:129]
def _update_go_terms_batch(self, updates: List[Tuple]) -> None: [lines:84]
def enrich_transcripts(self) -> None: [lines:99]
def _update_enriched_terms_batch(self, updates: List[Tuple]) -> None: [lines:69]
def run(self) -> None: [lines:38]
```

### filepath src/etl/id_enrichment.py

```python
class IDEnrichmentProcessor(BaseProcessor): [lines:947]
def __init__(self, config: Dict[str, Any]) -> None: [lines:36]
def download_uniprot_mapping(self) -> Path: [lines:19]
def _filter_uniprot_mapping(self, input_path: Path) -> Path: [lines:111]
def process_uniprot_mapping(self, mapping_file: Path) -> Dict[str, Dict[str, List[str]]]: [lines:139]
def update_transcript_ids(self, gene_mapping: Dict[str, Dict[str, List[str]]]) -> None: [lines:152]
def _update_id_batch(self, updates: List[Tuple]) -> None: [lines:57]
def _verify_id_updates(self) -> None: [lines:91]
def download_gene2ensembl(self) -> Path: [lines:19]
def process_gene2ensembl(self, mapping_file: Path) -> Dict[str, Dict[str, str]]: [lines:71]
def download_hgnc_complete(self) -> Path: [lines:19]
def process_hgnc_complete(self, hgnc_file: Path) -> Dict[str, str]: [lines:65]
def create_comprehensive_mapping(self) -> Dict[str, Dict[str, List[str]]]: [lines:97]
def run(self) -> None: [lines:56]
```

### filepath src/etl/pathways.py

```python
class PathwayProcessor(BaseProcessor): [lines:641]
def __init__(self, config: Dict[str, Any]) -> None: [lines:17]
def download_reactome(self) -> Path: [lines:19]
def process_pathways(self) -> Dict[str, Set[str]]: [lines:73]
def _extract_pathway_publications(self, evidence: str, pathway_id: str) -> List[Publication]: [lines:26]
def _save_pathway_publications(self, pathway_publications: Dict[str, List[Publication]]) -> None: [lines:15]
def _load_pathway_publications(self) -> Dict[str, List[Publication]]: [lines:25]
def _get_ncbi_mapping(self) -> Dict[str, str]: [lines:56]
def enrich_transcripts(self, gene_to_pathways: Dict[str, Set[str]]) -> None: [lines:130]
def _update_batch(self, updates: List[Tuple[List[str], str, str]]) -> None: [lines:39]
def extract_pathway_references(self, pathway_data: Dict[str, Any]) -> List[Publication]: [lines:29]
def integrate_pathways(self, pathway_data: Dict[str, List[Dict[str, Any]]]) -> None: [lines:148]
def _update_pathway_batch(self, updates: List[Tuple[str, List[str], List[str], str, str]]) -> None: [lines:29]
def run(self) -> None: [lines:20]
```

### filepath src/etl/pharmgkb_annotations.py

```python
class PharmGKBAnnotationsProcessor(BaseProcessor): [lines:1337]
def __init__(self, config: Dict[str, Any]) -> None: [lines:26]
def download_pharmgkb_data(self) -> Tuple[Path, Optional[Path], Optional[Path], Optional[Path]]: [lines:51]
def parse_gene_symbols(self, gene_string: str) -> List[str]: [lines:23]
def process_clinical_annotations(self, clinical_file: Path) -> Dict[str, List[Dict[str, Any]]]: [lines:120]
def process_vip_summaries(self, vip_file: Path) -> Dict[str, Dict[str, Any]]: [lines:57]
def process_pharmgkb_pathways(self, pathways_dir: Path) -> Dict[str, Dict[str, Any]]: [lines:236]
def process_variant_annotations(self, variant_file: Path) -> Dict[str, List[Dict[str, Any]]]: [lines:133]
def _calculate_variant_score(self, row: pd.Series) -> float: [lines:40]
def _assess_variant_evidence_level(self, row: pd.Series) -> str: [lines:19]
def _extract_metabolizer_info(self, variant_identifier: str, phenotype_category: str) -> Dict[str, Any]: [lines:44]
def _assess_clinical_actionability(self, significance: str, phenotype_category: str) -> str: [lines:17]
def extract_publication_references(self, gene_annotation_mapping: Dict[str, List[Dict[str, Any]]], variant_mapping: Optional[Dict[str, List[Dict[str, Any]]]] = None) -> List[Publication]: [lines:70]
def update_transcript_pharmgkb_data(self, gene_annotation_mapping: Dict[str, List[Dict[str, Any]]], vip_mapping: Optional[Dict[str, Dict[str, Any]]] = None, pathway_mapping: Optional[Dict[str, Dict[str, Any]]] = None, variant_mapping: Optional[Dict[str, List[Dict[str, Any]]]] = None) -> None: [lines:258]
def calculate_pharmgkb_scores(self) -> None: [lines:102]
def generate_pharmgkb_summary(self) -> None: [lines:55]
def run(self) -> None: [lines:67]
```

### filepath src/etl/products.py

```python
class ProductClassifier(BaseProcessor): [lines:521]
class ProductProcessor(BaseProcessor): [lines:356]
def integrate_products(self, product_data: Dict[str, Dict[str, Any]]) -> None: [lines:147]
def _update_product_batch(self, updates: List[Tuple[str, str, List[str], str]]) -> None: [lines:20]
def __init__(self, config: Dict[str, Any]) -> None: [lines:68]
def download_uniprot_data(self) -> Path: [lines:19]
def parse_uniprot_data(self, uniprot_file: Path) -> Dict[str, Dict[str, Any]]: [lines:154]
def update_gene_features(self, gene_data: Dict[str, Dict[str, Any]]) -> None: [lines:91]
def _update_feature_batch(self, updates: List[Tuple[str, str, str, List[str]]]) -> None: [lines:54]
def classify_gene(self, gene_data: Dict[str, Any]) -> List[str]: [lines:63]
def extract_publication_references(self, gene_data: Dict[str, Any]) -> List[Publication]: [lines:37]
def run(self) -> None: [lines:25]
def __init__(self, config: Dict[str, Any]) -> None: [lines:21]
def get_genes_with_features(self) -> List[Dict[str, Any]]: [lines:77]
def classify_genes(self, genes: List[Dict[str, Any]]) -> List[Tuple[str, List[str], List[Publication]]]: [lines:29]
def update_gene_types(self, classified_genes: List[Tuple[str, List[str], List[Publication]]]) -> None: [lines:160]
def run(self) -> None: [lines:62]
```

### filepath src/etl/publications.py

```python
class PublicationsProcessor(BaseProcessor): [lines:967]
def __init__(self, config: Dict[str, Any]) -> None: [lines:40]
def _load_cache(self) -> Dict[str, Dict[str, Any]]: [lines:20]
def _save_cache(self, cache: Dict[str, Dict[str, Any]]) -> None: [lines:17]
def create_publication_reference( pmid: str, evidence_type: str = "unknown", source_db: str = "PubMed", url: Optional[str] = None ) -> Publication: [lines:33]
def get_publication_metadata(self, pmid: str) -> Optional[Dict[str, Any]]: [lines:21]
def get_publications_metadata(self, pmids: List[str]) -> Dict[str, Dict[str, Any]]: [lines:38]
def _fetch_pubmed_metadata(self, pmids: List[str]) -> Dict[str, Dict[str, Any]]: [lines:69]
def _fetch_pubmed_summary(self, pmids: List[str]) -> Dict[str, Dict[str, Any]]: [lines:77]
def _fetch_pubmed_abstracts(self, pmids: List[str]) -> Dict[str, Dict[str, Any]]: [lines:68]
def enrich_publication_references(self) -> None: [lines:67]
def _update_publication_references(self, pub_metadata: Dict[str, Dict[str, Any]]) -> None: [lines:109]
def _execute_publication_updates(self, updates: List[Tuple[str, str, str]], section: str) -> None: [lines:36]
def _display_enrichment_statistics(self) -> None: [lines:67]
def enrich_publications_bulk(self, publications: List[Publication]) -> List[Publication]: [lines:66]
def run(self) -> None: [lines:24]
def integrate_publications(self, publications_data: Dict[str, List[Dict[str, Any]]]) -> None: [lines:142]
def _update_publication_batch(self, updates: List[Tuple[str, List[str], List[str], str]]) -> None: [lines:20]
def _format_publications(self, publications: List[Dict[str, Any]]) -> List[Dict[str, Any]]: [lines:32]
```

### filepath src/etl/scoring_analytics.py

```python
class ScoringAnalytics: [lines:16]
class ScoringAnalyticsProcessor(BaseProcessor): [lines:601]
def __init__(self, config: Dict[str, Any]) -> None: [lines:23]
def analyze_gene_evidence_profile(self, gene_symbol: str) -> Optional[ScoringAnalytics]: [lines:65]
def _calculate_analytics_metrics( self, gene_symbol: str, evidence_scores: List[Dict[str, Any]], use_case_scores: Dict[str, float], drug_scores: Dict[str, List[float]], total_evidence_items: int, drugs: Dict[str, Any], pathways: List[str], go_terms: Dict[str, Any], [lines:111]
def _identify_evidence_gaps( self, diversity: float, clinical: float, mechanistic: float, publication: float, genomic: float, safety: float ) -> List[str]: [lines:31]
def _generate_recommendations( self, gene_symbol: str, use_case_rankings: Dict[str, float], evidence_gaps: List[str], clinical_strength: float, confidence: float ) -> List[str]: [lines:53]
def generate_comparative_analysis(self, gene_list: List[str]) -> Dict[str, Any]: [lines:38]
def _rank_genes_by_metrics(self, gene_analytics: Dict[str, ScoringAnalytics]) -> Dict[str, List[Dict[str, Any]]]: [lines:50]
def _compare_use_cases(self, gene_analytics: Dict[str, ScoringAnalytics]) -> Dict[str, Any]: [lines:31]
def _analyze_evidence_quality(self, gene_analytics: Dict[str, ScoringAnalytics]) -> Dict[str, Any]: [lines:26]
def _assess_clinical_readiness(self, gene_analytics: Dict[str, ScoringAnalytics]) -> Dict[str, List[str]]: [lines:24]
def _prioritize_research_opportunities(self, gene_analytics: Dict[str, ScoringAnalytics]) -> List[Dict[str, Any]]: [lines:35]
def _generate_portfolio_recommendations(self, gene_analytics: Dict[str, ScoringAnalytics]) -> List[str]: [lines:44]
def export_analytics_report(self, gene_list: List[str], output_file: str) -> bool: [lines:55]
```

### filepath src/etl/transcript.py

```python
class TranscriptProcessor(BaseProcessor): [lines:292]
def __init__(self, config: Dict[str, Any]) -> None: [lines:26]
def download_gtf(self) -> Path: [lines:20]
def parse_gtf(self, gtf_path: Path) -> pd.DataFrame: [lines:92]
def load_transcripts(self, transcripts: pd.DataFrame) -> None: [lines:115]
def run(self) -> None: [lines:28]
```

### filepath src/migrations/remove_migration_files.py

```python
def find_migration_files(base_dir: str = "src/migrations") -> List[Path]: [lines:28]
def remove_files(files: List[Path], dry_run: bool = True) -> None: [lines:13]
```

### filepath src/utils/__init__.py

```python

```

### filepath src/utils/download.py

```python
def download_file( url: str, destination: Union[str, Path], module_name: str = "download", force_download: bool = False, headers: Optional[Dict[str, str]] = None ) -> bool: [lines:86]
def extract_gzip( source: Union[str, Path], destination: Optional[Union[str, Path]] = None, remove_source: bool = False ) -> bool: [lines:39]
```

### filepath src/utils/gene_matcher.py

```python
def normalize_gene_symbol(symbol: str) -> str: [lines:34]
def match_exact(symbol: str, targets: Union[List[str], Set[str], Dict[str, Any]]) -> Optional[str]: [lines:29]
def build_normalized_map(genes: Union[List[str], Set[str]]) -> Dict[str, str]: [lines:19]
def match_genes_bulk(query_genes: List[str], target_genes: List[str], use_fuzzy: bool = False) -> Dict[str, str]: [lines:70]
def levenshtein_distance(s1: str, s2: str) -> int: [lines:31]
def get_gene_match_stats( query_genes: List[str], matched_genes: Dict[str, str] ) -> Dict[str, Any]: [lines:22]
```

### filepath src/utils/logging.py

```python
class UnifiedProgressBar: [lines:140]
class ProgressManager: [lines:125]
def get_progress_manager() -> ProgressManager: [lines:11]
def get_progress_bar(total: int, desc: str, module_name: str = "mediabase", unit: str = "it") -> UnifiedProgressBar: [lines:17]
def create_download_progress_bar(desc: str, total: int, module_name: str) -> UnifiedProgressBar: [lines:13]
def get_progress() -> Progress: [lines:8]
class LoggerStreamCapture(io.StringIO): [lines:38]
class CustomTqdmHandler(logging.Handler): [lines:27]
def complete_all_progress_bars() -> None: [lines:9]
def setup_logging( log_level: Union[int, str] = DEFAULT_LOG_LEVEL, log_file: Optional[str] = None, module_name: str = "mediabase", console_output: bool = True, rich_output: bool = True, ) -> logging.Logger: [lines:88]
def get_etl_logger( module_name: str, log_level: Union[int, str] = DEFAULT_LOG_LEVEL, log_file: Optional[str] = None ) -> logging.Logger: [lines:32]
def __init__(self, total: int, desc: str, module_name: str = "mediabase", unit: str = "it") -> None: [lines:31]
def update(self, n: int = 1) -> None: [lines:18]
def update_float(self, value: float) -> None: [lines:20]
def _update_progress(self) -> None: [lines:46]
def complete(self) -> None: [lines:7]
def close(self) -> None: [lines:10]
def __init__(self): [lines:5]
def create_bar(self, total: int, desc: str, module_name: str = "mediabase", unit: str = "it") -> UnifiedProgressBar: [lines:28]
def _create_tracked_bar(self, bar: UnifiedProgressBar, bar_id: int) -> UnifiedProgressBar: [lines:27]
def complete_all_bars(self) -> None: [lines:14]
def create_download_bar(self, desc: str, total: int, module_name: str) -> UnifiedProgressBar: [lines:24]
def get_or_create_rich_progress(self) -> Progress: [lines:19]
def __init__(self, original_stream=None): [lines:5]
def write(self, s: str) -> int: [lines:25]
def set_progress_active(self, active: bool = True): [lines:3]
def __init__(self, level=logging.NOTSET): [lines:4]
def emit(self, record): [lines:19]
def format_time(seconds): [lines:8]
def tracked_close(): [lines:8]
```

### filepath src/utils/pandas_helpers.py

```python
class PandasOperationSafe: [lines:19]
def safe_operation(func): [lines:7]
def safe_assign(df: pd.DataFrame, column: str, value: Any) -> pd.DataFrame: [lines:19]
def safe_batch_assign(df: pd.DataFrame, columns_dict: Dict[str, Any]) -> pd.DataFrame: [lines:16]
def safe_fillna(df: pd.DataFrame, column: str, value: Any) -> pd.DataFrame: [lines:18]
def get_column_safely(df: pd.DataFrame, column: str, default: Any = None) -> pd.Series: [lines:16]
def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame: [lines:27]
def __init__(self, warning_type=None): [lines:7]
def __enter__(self): [lines:4]
def __exit__(self, exc_type, exc_val, exc_tb): [lines:3]
def wrapper(*args, **kwargs): [lines:3]
```

### filepath src/utils/progress.py

```python
def track_progress( iterable: Iterable[T], total: Optional[int] = None, desc: str = "Processing", module_name: str = "progress", unit: str = "items" ) -> Iterator[T]: [lines:46]
def tqdm_with_logging( iterable: Iterable[T], desc: str = "Processing", module_name: str = "mediabase", total: Optional[int] = None, unit: str = "it" ) -> Iterator[T]: [lines:23]
class tqdm_replacement: [lines:17]
def patch_tqdm_globally(): [lines:14]
class SuppressPandasWarnings: [lines:18]
def suppress_pandas_warnings(func): [lines:7]
def safe_dataframe_assign(df: pd.DataFrame, col: str, value: Any) -> pd.DataFrame: [lines:15]
def batch_process( items: List[T], batch_size: int, process_func: Callable[[List[T]], Any], desc: str = "Processing batches", module_name: str = "batch" ) -> List[Any]: [lines:54]
def progress_decorator( desc: str = "Processing", module_name: Optional[str] = None, log_result: bool = True ) -> Callable: [lines:47]
def tqdm( iterable: Iterable[T], desc: str = "Processing", total: Optional[int] = None, **kwargs ) -> Iterator[T]: [lines:13]
def __init__(self, warning_type=None): [lines:7]
def __enter__(self): [lines:3]
def __exit__(self, exc_type, exc_val, exc_tb): [lines:3]
def wrapper(*args, **kwargs): [lines:3]
def decorator(func: Callable) -> Callable: [lines:31]
def wrapper(*args: Any, **kwargs: Any) -> Any: [lines:28]
```

### filepath src/utils/publication_types.py

```python
class Publication(TypedDict, total=False): [lines:13]
```

### filepath src/utils/publication_utils.py

```python
def is_valid_pmid(pmid: str) -> bool: [lines:11]
def extract_pmid_from_text(text: str) -> Optional[str]: [lines:21]
def extract_pmids_from_urls(url1: str = None, url2: str = None) -> List[str]: [lines:29]
def extract_pmids_from_text(text: str) -> List[str]: [lines:37]
def format_pmid_url(pmid: str) -> str: [lines:10]
def format_publication_citation(pub: Publication) -> str: [lines:37]
def merge_publication_references(pub1: Publication, pub2: Publication) -> Publication: [lines:32]
def extract_dois_from_text(text: str) -> List[str]: [lines:30]
def extract_pmc_ids_from_text(text: str) -> List[str]: [lines:30]
def extract_clinical_trial_ids_from_text(text: str) -> List[str]: [lines:34]
def extract_all_publication_identifiers(text: str) -> Dict[str, List[str]]: [lines:35]
def format_publication_url(identifier: str, identifier_type: str) -> str: [lines:27]
def calculate_publication_impact_score(publication: Publication) -> float: [lines:68]
def assess_publication_relevance(publication: Publication, context: Dict[str, Any]) -> float: [lines:74]
def get_journal_impact_estimates() -> Dict[str, float]: [lines:33]
def enhance_publication_with_metrics(publication: Publication, context: Optional[Dict[str, Any]] = None) -> Publication: [lines:67]
def rank_publications_by_relevance(publications: List[Publication], context: Dict[str, Any]) -> List[Publication]: [lines:29]
def sort_key(pub): [lines:5]
```

### filepath src/utils/validation.py

```python
def validate_gene_symbol(gene_symbol: str) -> bool: [lines:22]
def validate_config(config: Dict[str, Any], required_keys: list[str], defaults: Dict[str, Any]) -> Dict[str, Any]: [lines:24]
def validate_db_config(config: Dict[str, Any]) -> Dict[str, Any]: [lines:25]
def validate_transcript_data(df: pd.DataFrame) -> bool: [lines:64]
def valid_coordinates(coord: Dict[str, Any]) -> bool: [lines:11]
```

### filepath tests/conftest.py

```python
def test_db(): [lines:65]
```

### filepath tests/db/test_schema_migrations.py

```python
def db_config() -> Dict[str, Any]: [lines:9]
def test_v0_1_5_migration(db_config: Dict[str, Any]) -> None: [lines:47]
def test_source_references_default(db_config: Dict[str, Any]) -> None: [lines:31]
def test_publication_reference_type_usage(db_config: Dict[str, Any]) -> None: [lines:32]
```

### filepath tests/etl/test_drugs.py

```python
def test_config(): [lines:8]
def sample_drug_data(tmp_path) -> Path: [lines:20]
def test_process_drug_targets(sample_drug_data, test_config): [lines:14]
def test_integrate_drugs(test_config): [lines:24]
def test_calculate_drug_scores(test_config): [lines:9]
```

### filepath tests/etl/test_go_terms.py

```python
def test_config(): [lines:13]
def sample_obo_data(tmp_path) -> Path: [lines:25]
def test_load_go_graph(sample_obo_data, test_config): [lines:12]
def test_get_ancestors(sample_obo_data, test_config): [lines:14]
def test_enrich_transcripts(test_config): [lines:14]
def test_populate_initial_terms(test_config, sample_obo_data): [lines:38]
```

### filepath tests/etl/test_integration.py

```python
def test_db(): [lines:45]
def test_full_etl_pipeline(test_db): [lines:42]
```

### filepath tests/etl/test_integration_products.py

```python
def mock_uniprot_data(tmp_path): [lines:36]
def test_genes(): [lines:8]
def test_product_classification(mock_uniprot_data, test_genes, monkeypatch): [lines:27]
def test_invalid_gene_symbols(mock_uniprot_data, monkeypatch): [lines:11]
def test_database_update(mock_uniprot_data, monkeypatch): [lines:32]
```

### filepath tests/etl/test_products.py

```python
def mock_uniprot_data(tmp_path): [lines:27]
def test_product_classification(mock_uniprot_data, monkeypatch): [lines:14]
def test_invalid_gene_symbol(mock_uniprot_data, monkeypatch): [lines:7]
def test_database_update(mock_uniprot_data, monkeypatch): [lines:6]
```

### filepath tests/etl/test_publications.py

```python
def mock_config() -> Dict[str, Any]: [lines:12]
def mock_db_manager(mock_config): [lines:8]
def processor(mock_config, mock_db_manager): [lines:3]
def test_init(processor, mock_config): [lines:5]
def test_fetch_pubmed_metadata(processor): [lines:23]
def test_update_batch(processor, mock_db_manager): [lines:11]
def test_enrich_references_integration(processor, mock_db_manager): [lines:28]
def test_error_handling(processor, mock_db_manager): [lines:8]
```

### filepath tests/etl/test_transcript.py

```python
def test_config(): [lines:13]
def sample_gtf_data(tmp_path) -> Path: [lines:12]
def mock_gtf_data(): [lines:17]
def test_process_gtf(sample_gtf_data, test_config): [lines:17]
def test_validate_transcript_data(test_config): [lines:20]
def test_extract_alt_ids(mock_gtf_data): [lines:12]
def test_full_pipeline(test_config): [lines:14]
```

### filepath tests/test_api/test_basic.py

```python

```

### filepath tests/test_db/test_basic.py

```python

```

### filepath tests/test_etl/test_basic.py

```python

```

### filepath tests/test_patient_copy.py

```python
class TestPatientDatabaseCreator: [lines:340]
class TestCSVValidationEdgeCases: [lines:79]
class TestIntegrationScenarios: [lines:52]
def valid_csv_data(self) -> pd.DataFrame: [lines:7]
def invalid_csv_data(self) -> pd.DataFrame: [lines:6]
def alternative_csv_data(self) -> pd.DataFrame: [lines:6]
def csv_file(self, tmp_path: Path, valid_csv_data: pd.DataFrame) -> Path: [lines:5]
def db_config(self) -> Dict[str, Any]: [lines:9]
def creator(self, csv_file: Path, db_config: Dict[str, Any]) -> PatientDatabaseCreator: [lines:3]
def test_init(self, creator: PatientDatabaseCreator): [lines:8]
def test_validate_csv_file_success(self, creator: PatientDatabaseCreator): [lines:11]
def test_validate_csv_file_empty(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:11]
def test_validate_csv_file_missing_columns(self, tmp_path: Path, db_config: Dict[str, Any], invalid_csv_data: pd.DataFrame): [lines:12]
def test_find_column_mapping_automatic(self, creator: PatientDatabaseCreator): [lines:6]
def test_find_column_mapping_alternatives(self, creator: PatientDatabaseCreator): [lines:6]
def test_find_column_mapping_case_insensitive(self, creator: PatientDatabaseCreator): [lines:6]
def test_find_column_mapping_incomplete(self, creator: PatientDatabaseCreator): [lines:6]
def test_validate_mapped_columns_success(self, creator: PatientDatabaseCreator, valid_csv_data: pd.DataFrame): [lines:11]
def test_validate_mapped_columns_with_nulls(self, creator: PatientDatabaseCreator): [lines:17]
def test_validate_mapped_columns_invalid_numbers(self, creator: PatientDatabaseCreator): [lines:12]
def test_create_target_database_new(self, mock_connect: Mock, creator: PatientDatabaseCreator): [lines:22]
def test_create_target_database_overwrite(self, mock_confirm: Mock, mock_connect: Mock, creator: PatientDatabaseCreator): [lines:19]
def test_create_target_database_cancelled(self, mock_confirm: Mock, mock_connect: Mock, creator: PatientDatabaseCreator): [lines:16]
def test_copy_database_content(self, mock_remove: Mock, mock_exists: Mock, mock_system: Mock, creator: PatientDatabaseCreator): [lines:9]
def test_update_fold_changes_success(self, mock_get_db: Mock, creator: PatientDatabaseCreator): [lines:25]
def test_update_fold_changes_partial(self, mock_get_db: Mock, creator: PatientDatabaseCreator): [lines:25]
def test_update_fold_changes_database_error(self, mock_get_db: Mock, creator: PatientDatabaseCreator): [lines:9]
def test_validate_result(self, mock_get_db: Mock, creator: PatientDatabaseCreator): [lines:20]
def test_validate_result_error(self, mock_get_db: Mock, creator: PatientDatabaseCreator): [lines:6]
def db_config(self) -> Dict[str, Any]: [lines:9]
def test_mixed_case_columns(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:15]
def test_extra_columns(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:18]
def test_scientific_notation_fold_values(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:15]
def test_negative_fold_values(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:14]
def db_config(self) -> Dict[str, Any]: [lines:9]
def test_full_pipeline_dry_run(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:19]
def test_large_csv_handling(self, tmp_path: Path, db_config: Dict[str, Any]): [lines:17]
```

### filepath tests/utils/test_publication_utils.py

```python
def test_is_valid_pmid(pmid: str, expected: bool) -> None: [lines:3]
def test_extract_pmid_from_text(text: str, expected: str | None) -> None: [lines:3]
def test_extract_multiple_pmids() -> None: [lines:11]
def test_format_pmid_url() -> None: [lines:6]
def test_format_publication_citation() -> None: [lines:13]
def test_format_publication_citation_many_authors() -> None: [lines:13]
def test_merge_publication_references() -> None: [lines:27]
def test_merge_publication_references_empty_values() -> None: [lines:21]
```

### filepath tests/utils/test_validation.py

```python
def test_validate_gene_symbol(): [lines:13]
def test_validate_config(): [lines:20]
def test_validate_db_config(): [lines:29]
```

---
Generated by project2md on 2025-07-20 15:18:12
